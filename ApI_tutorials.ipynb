{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d113c4c-b087-4208-be62-d200966961e1",
   "metadata": {},
   "source": [
    "## **Extracting Website Data with APIs and JSON: A Step-by-Step Guide**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe6f723-2902-4bb7-8def-ed500cc0a283",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step1: Get your API\n",
    "Get your API (for free ones, just search for free API on google\n",
    "\n",
    "for this tutorials, I will be using this:\n",
    "http://universities.hipolabs.com/search?country=United+States)\n",
    "\n",
    "The above API allow users to get a list of universities in a specified country."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a10200-b39e-4682-874a-bf5853914f25",
   "metadata": {},
   "source": [
    "# Step 2: Import Necessary Libraries\n",
    "\n",
    "Before we can fetch and process the data from the API, we need to import a few libraries. These libraries will help us handle the HTTP requests, parse the JSON data, and work with the data in a tabular format.\n",
    "\n",
    "Add the following code to your Python script:\n",
    "\n",
    "**Explanation:**\n",
    "import json: This library is used to parse JSON (JavaScript Object Notation) data, which is a common format for data exchange between a client and a server.\n",
    "\n",
    "import urllib.parse: This module helps with parsing URLs and handling query strings.\n",
    "\n",
    "import urllib.request: This module allows you to make HTTP requests to fetch data from the internet.\n",
    "\n",
    "import pandas as pd: Pandas is a powerful data manipulation and analysis library in Python. We will use it to organize the data in a tabular format (dataframes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affba8b0-23c3-434b-ab9a-53025b53aa7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7245c1-a2ea-442d-8afc-d84f5b07083e",
   "metadata": {},
   "source": [
    "# Step 3: Construct the API Request URL\n",
    "Now, we need to construct the URL for our API request based on the user input. This will allow us to get the list of universities for the specified country.\n",
    "\n",
    "Add the following code to your script:\n",
    "\n",
    "Explanation:\n",
    "location = input(\"Enter the name of the country whose universities you are interested in: \"): This line prompts the user to input the name of the country. The entered value is stored in the variable location.\n",
    "\n",
    "q = {\"country\": location}: We create a dictionary with the key \"country\" and the value as the user-provided location. This dictionary will be used to construct the query string for the API request.\n",
    "\n",
    "url = \"http://universities.hipolabs.com/search?\" + urllib.parse.urlencode(q): This line constructs the full API request URL by appending the URL-encoded query string to the base URL. \n",
    "\n",
    "The urllib.parse.urlencode(q) function converts the dictionary q into a query string format (e.g., country=United+States).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0ed0584-27c1-4480-84f8-88a5f42c189e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter name of country whose universities you are interested canada\n"
     ]
    }
   ],
   "source": [
    "location = input(\"enter name of country whose universities you are interested\")\n",
    "q = {\"country\" : location}\n",
    "url = \"http://universities.hipolabs.com/search?\" + urllib.parse.urlencode(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2596741-eb67-4d84-9e08-0cc77e7972e5",
   "metadata": {},
   "source": [
    "# Step 4: Fetch Data from the API\n",
    "\n",
    "With the API request URL ready, we can now fetch the data from the API. Add the following code to your script:\n",
    "\n",
    "Explanation:\n",
    "\n",
    "with urllib.request.urlopen(url) as response:: This line opens the URL and sends a request to the API. The urlopen function returns a response object, which we can read from. The with statement ensures that the response is properly closed after we're done with it.\n",
    "\n",
    "page = json.loads(response.read().decode()):\n",
    "response.read(): This reads the raw data from the response.\n",
    ".decode(): This decodes the raw bytes into a string using UTF-8 encoding.\n",
    "\n",
    "json.loads(): This parses the JSON string into a Python dictionary or list (depending on the JSON structure). The parsed JSON data is stored in the variable page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a74bfa4-f6ed-4caa-838e-daf513d2bf29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(url) as response:\n",
    "    page = json.loads(response.read().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05d1b19-6336-4a19-91ca-e3cc04daeb46",
   "metadata": {},
   "source": [
    "# Step 5: Extract and Store Specific Information\n",
    "Now that we have the data, we need to extract specific pieces of information (university name, state/province, and website) and store them in lists. Add the following code to your script:\n",
    "\n",
    "Explanation:\n",
    "Lists Initialization: We initialize three empty lists: school_name, province, and website to store the extracted information.\n",
    "\n",
    "school_name = []: List to store university names.\n",
    "province = []: List to store state or province names.\n",
    "website = []: List to store university websites.\n",
    "For Loop: We iterate over each item (university) in the page list.\n",
    "\n",
    "for info in page:: Iterates through each university's information in the JSON data.\n",
    "Extract Information:\n",
    "\n",
    "name = info.get(\"name\", \"Nil\"): Retrieves the university's name. If the name is not available, it defaults to \"Nil\".\n",
    "location = info.get(\"state-province\", \"Nil\"): Retrieves the state or province of the university. If not available, defaults to \"Nil\".\n",
    "web = info.get(\"web_pages\", \"Nil\")[0]: Retrieves the first website URL from the list of web pages. If not available, defaults to \"Nil\".\n",
    "Append to Lists:\n",
    "\n",
    "school_name.append(name): Adds the university name to the school_name list.\n",
    "province.append(location): Adds the state or province to the province list.\n",
    "website.append(web): Adds the website URL to the website list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "854c9b3d-b08e-4ab0-8f22-0f35c54cf6be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "school_name = []\n",
    "province = []\n",
    "website = []\n",
    "\n",
    "for info in page:\n",
    "    name = info.get(\"name\", \"Nil\")\n",
    "    location = info.get(\"state-province\", \"Nil\")\n",
    "    web = info.get(\"web_pages\", \"Nil\")[0]\n",
    "    \n",
    "    \n",
    "    school_name.append(name)\n",
    "    province.append(location)\n",
    "    website.append(web)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7361a7-6d64-4ff1-b98f-c7b0040900df",
   "metadata": {},
   "source": [
    "# Step 6: Create a DataFrame\n",
    "Finally, we will organize the extracted data into a pandas DataFrame. A DataFrame is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns).\n",
    "\n",
    "Add the following code to your script:\n",
    "\n",
    "Explanation:\n",
    "pd.DataFrame(): This function creates a DataFrame from the provided data.\n",
    "{\"University\": school_name, \"State\": province, \"Uni Site\": website}: We pass a dictionary where the keys are the column names (\"University\", \"State\", and \"Uni Site\") and the values are the lists containing the data for each column.\n",
    "The resulting DataFrame will have three columns: \"University\", \"State\", and \"Uni Site\", populated with the respective data from the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e99a8f10-12c6-4005-ad25-e8b310fb28e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = pd.DataFrame({\"University\": school_name,\n",
    "                      \"State\" : province,\n",
    "                      \"Uni Site\" : website})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3764fb-341b-41fc-9cbe-e14b9fef2d7b",
   "metadata": {},
   "source": [
    "# Step 7: Display the Data\n",
    "To verify that our DataFrame has been created correctly, we will print the first 10 rows of the DataFrame. Add the following code to your script:\n",
    "Explanation:\n",
    "print(table.head(10)): The head() function in pandas returns the first n rows of the DataFrame. By passing 10 as an argument, we request the first 10 rows. The print() function then prints these rows to the console.\n",
    "This step allows us to quickly inspect the DataFrame and ensure that the data has been correctly extracted and organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd24bee0-82bb-4982-9a4f-ff4f8f9a7c5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              University             State                          Uni Site\n",
      "0  Cégep de Saint-Jérôme            Quebec            https://www.cstj.qc.ca\n",
      "1        Lambton College           Ontario     https://www.lambtoncollege.ca\n",
      "2      Acadia University       Nova Scotia            http://www.acadiau.ca/\n",
      "3      Algonquin College           Ontario  http://www.algonquincollege.com/\n",
      "4         Ashton College  British Columbia     http://www.ashtoncollege.com/\n"
     ]
    }
   ],
   "source": [
    "print(table.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca6705-486c-4010-a764-6b0faead6349",
   "metadata": {},
   "source": [
    "# Step 8: Save the Data (You will have to run this line of code Yourself, just follow the instructions below)\n",
    "\n",
    "Now that we have extracted and organized the data into a DataFrame, we can save it to a CSV file to see the full details or sharing with others. \n",
    "\n",
    "# To save the DataFrame to a CSV file, follow these steps:\n",
    "\n",
    "Choose a Name: Decide on a name for your CSV file. This will be used to identify the file on your device.\n",
    "\n",
    "Use the to_csv Method: Use the to_csv method available in pandas to save the DataFrame to a CSV file. \n",
    "\n",
    "# Here's how to do it:\n",
    "\n",
    "#### *table.to_csv(\"universities_data.csv\")*\n",
    "\n",
    "Replace \"universities_data.csv\" with the desired name for your CSV file. Make sure to keep the .csv extension at the end of the filename.\n",
    "\n",
    "Run the Code: Execute the above line of code in your Python environment. This will generate a CSV file with the specified name containing the data from the DataFrame.\n",
    "\n",
    "Locate the File: Once the code is executed successfully, you can find the CSV file in the same directory where your Python script is located.\n",
    "\n",
    "Now, you have successfully saved the extracted university data to a CSV file on your device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "289f628c-13d8-4fa9-985d-a561f2fa21b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the code Here:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813a38fa-304a-48f4-8acd-b5450e3897d4",
   "metadata": {},
   "source": [
    "# Final Note \n",
    "\n",
    "Congratulations on completing this tutorial! You've learned how to extract data from a web API, process it using Python, and organize it into a tabular format. By following these steps, you've gained valuable skills that can be applied to a wide range of data extraction and analysis tasks.\n",
    "\n",
    "Remember, the ability to work with APIs and manipulate data programmatically is a powerful skill in today's data-driven world. Whether you're a student, a researcher, or a professional in any field, these skills will serve you well in your endeavors.\n",
    "\n",
    "Feel free to explore further, experiment with different APIs, and continue building your Python skills. Don't hesitate to reach out if you have any questions or need assistance.\n",
    "\n",
    "*Keep coding, keep learning, and keep exploring new possibilities! Happy coding!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
